{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61b740b0",
   "metadata": {},
   "source": [
    "# Import thư viện"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c1a4fe",
   "metadata": {},
   "source": [
    "### Nạp thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e458725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from -r req.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: torch in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from -r req.txt (line 2)) (2.7.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from -r req.txt (line 3)) (3.5.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from -r req.txt (line 4)) (4.51.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from -r req.txt (line 5)) (1.6.1)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from -r req.txt (line 6)) (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from pandas->-r req.txt (line 1)) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from pandas->-r req.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from pandas->-r req.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from pandas->-r req.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from torch->-r req.txt (line 2)) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from torch->-r req.txt (line 2)) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from torch->-r req.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from torch->-r req.txt (line 2)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from torch->-r req.txt (line 2)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from torch->-r req.txt (line 2)) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from torch->-r req.txt (line 2)) (80.1.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from datasets->-r req.txt (line 3)) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from datasets->-r req.txt (line 3)) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from datasets->-r req.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from datasets->-r req.txt (line 3)) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from datasets->-r req.txt (line 3)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from datasets->-r req.txt (line 3)) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from datasets->-r req.txt (line 3)) (3.11.18)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from datasets->-r req.txt (line 3)) (0.30.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from datasets->-r req.txt (line 3)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from datasets->-r req.txt (line 3)) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from transformers->-r req.txt (line 4)) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from transformers->-r req.txt (line 4)) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from transformers->-r req.txt (line 4)) (0.5.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from scikit-learn->-r req.txt (line 5)) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from scikit-learn->-r req.txt (line 5)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from scikit-learn->-r req.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from accelerate>=0.26.0->-r req.txt (line 6)) (7.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from aiohttp->datasets->-r req.txt (line 3)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from aiohttp->datasets->-r req.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from aiohttp->datasets->-r req.txt (line 3)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from aiohttp->datasets->-r req.txt (line 3)) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from aiohttp->datasets->-r req.txt (line 3)) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from aiohttp->datasets->-r req.txt (line 3)) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from aiohttp->datasets->-r req.txt (line 3)) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->-r req.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from requests>=2.32.2->datasets->-r req.txt (line 3)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from requests>=2.32.2->datasets->-r req.txt (line 3)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from requests>=2.32.2->datasets->-r req.txt (line 3)) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from requests>=2.32.2->datasets->-r req.txt (line 3)) (2025.4.26)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from sympy>=1.13.3->torch->-r req.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from tqdm>=4.66.3->datasets->-r req.txt (line 3)) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\qscvd\\onedrive\\documents\\github\\makerthon\\phobert-finetuning\\venv\\lib\\site-packages (from jinja2->torch->-r req.txt (line 2)) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -r req.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906f6fd6",
   "metadata": {},
   "source": [
    "### Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2feaad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc95d5a",
   "metadata": {},
   "source": [
    "# Tiền xử lí dữ liệu\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddd61ad",
   "metadata": {},
   "source": [
    "### Nạp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bcb510",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"vinai/phobert-base\", num_labels=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bb595d",
   "metadata": {},
   "source": [
    "#### lưu model (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e308f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"model\")\n",
    "tokenizer.save_pretrained(\"tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f1a5f5",
   "metadata": {},
   "source": [
    "### Nạp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31afce90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Danh sách nhãn gốc: ['clear_history' 'find_api' 'find_history' 'find_news' 'log_in' 'log_out']\n",
      "Các nhãn đã mã hóa: [2 1 5 4 5 4 1 1 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0]\n",
      "[2, 1, 5, 4, 5, 4, 1, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Tải dữ liệu từ file CSV\n",
    "dataset = load_dataset(\"csv\", data_files={\"train\": \"dataset.csv\", \"test\": \"dataset.csv\"})\n",
    "\n",
    "# Lấy danh sách các nhãn gốc từ cột 'intent'\n",
    "intent_labels = dataset[\"train\"][\"intent\"]  # Cột 'intent' chứa các nhãn gốc\n",
    "\n",
    "# Khởi tạo LabelEncoder để mã hóa nhãn thành chỉ số\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Mã hóa các nhãn gốc thành các chỉ số\n",
    "label_encoder.fit(intent_labels)  # Fit trên toàn bộ nhãn từ cột 'intent'\n",
    "\n",
    "# In ra các nhãn gốc và các chỉ số đã mã hóa\n",
    "print(\"Danh sách nhãn gốc:\", label_encoder.classes_)  # In mảng nhãn gốc\n",
    "print(\"Các nhãn đã mã hóa:\", label_encoder.transform(intent_labels))  # In nhãn đã mã hóa thành chỉ số\n",
    "\n",
    "# Mã hóa nhãn intent thành chỉ số và tokenize văn bản\n",
    "def encode_labels_and_tokenize(examples):\n",
    "    # Tokenize văn bản\n",
    "    tokenized = tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=13)\n",
    "    \n",
    "    # Mã hóa intent thành nhãn (labels) sử dụng LabelEncoder đã được fit\n",
    "    tokenized[\"labels\"] = label_encoder.transform(examples[\"intent\"])  # Mã hóa nhãn thành chỉ số\n",
    "    \n",
    "    return tokenized\n",
    "\n",
    "# Áp dụng mã hóa nhãn và tokenization cho cả train và test dataset\n",
    "train_dataset = dataset[\"train\"].map(encode_labels_and_tokenize, batched=True)\n",
    "test_dataset = dataset[\"test\"].map(encode_labels_and_tokenize, batched=True)\n",
    "\n",
    "# Kiểm tra dữ liệu sau khi mã hóa nhãn và tokenization\n",
    "  \n",
    "print(train_dataset[\"labels\"])  # Hiển thị mẫu đầu tiên trong train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66f390f",
   "metadata": {},
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fe24b8",
   "metadata": {},
   "source": [
    "### Cấu hình tham số huấn luyện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d3ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    logging_dir='./logs',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10  \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8f4636",
   "metadata": {},
   "source": [
    "### Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd79c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "\n",
    "from google.colab import files\n",
    "files.download('results')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
